{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xlwings as xw\n",
    "from datetime import datetime, date\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得n日前日期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(days):\n",
    "    # 格式化為 月/日 形式 \n",
    "    return((date.today() - timedelta(days)).strftime(\"%m/%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 獲取兩個日期間所有日期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEveryDay(begin_date,end_date):\n",
    "    date_list = []\n",
    "    begin_date = datetime.datetime.strptime(begin_date, \"%m/%d\")\n",
    "    end_date = datetime.datetime.strptime(end_date,\"%m/%d\")\n",
    "    while begin_date <= end_date:\n",
    "        date_str = begin_date.strftime(\"%m/%d\")\n",
    "        date_list.append(date_str)\n",
    "        begin_date += datetime.timedelta(days=1)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取頁面url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_url(days,current_page = 'https://www.ptt.cc/bbs/MobileComm/index.html'):\n",
    "    my_headers = {'cookie': 'over18=1;'}\n",
    "    resp = requests.get(current_page, headers = my_headers)\n",
    "    c_content = BeautifulSoup(resp.content, 'html.parser')\n",
    "    # current page date\n",
    "    c_date = []\n",
    "    for c in c_content.find_all('div',class_='r-ent'):\n",
    "        category = c.find(class_='title').text[:5]\n",
    "        if ('[公告]') not in category:\n",
    "            if ('[協尋]') not in category:\n",
    "                c_date.append(c.find('div', class_='date').text.replace(' ','0'))\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    all_url = []   \n",
    "\n",
    "    while set(c_date) & (set(days)):\n",
    "        all_url.append(current_page)\n",
    "\n",
    "        #go to previous page \n",
    "        previous_page = 'https://www.ptt.cc' + c_content.find_all('a', class_='btn wide')[1]['href']\n",
    "        p_resp = requests.get(previous_page, headers = my_headers)\n",
    "        p_content = BeautifulSoup(p_resp.content, 'html.parser')\n",
    "        p_date = []\n",
    "        for p in p_content.find_all('div', class_=\"date\"):\n",
    "            if p not in p_date:\n",
    "                p_date.append(p.text.replace(' ', '0'))\n",
    "\n",
    "        # renew current content,date\n",
    "        c_content = p_content\n",
    "        c_date = p_date\n",
    "        current_page = previous_page\n",
    "    else:\n",
    "        return all_url\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  爬取當前頁面資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppt_web_crawler(homepage_url, get_date):\n",
    "    my_headers = {'cookie': 'over18=1;'}\n",
    "    resp = requests.get(homepage_url, headers = my_headers)\n",
    "    content = BeautifulSoup(resp.content, 'html.parser')\n",
    "    category = content.find('a', class_='board').text.replace('看板 ','PTT : ')\n",
    "    articles_content = content.select(\".r-ent\")\n",
    "    # upvote, title, author, date, url\n",
    "    articles = []\n",
    "    for ar in articles_content:\n",
    "        article = {}\n",
    "        if ar.find('a'):\n",
    "            \n",
    "            upvote = ar.find(class_='nrec').text\n",
    "            title = ar.find('a').text\n",
    "            url = \"https://www.ptt.cc\" + ar.find('a')['href']      \n",
    "            author = ar.find(class_='author').text\n",
    "            date = ar.find(class_='date').text.replace(' ','0')\n",
    "\n",
    "            article['source'] = category\n",
    "            article['upvote'] = upvote\n",
    "            article['title'] = title\n",
    "            article['author'] = author\n",
    "            article['date'] = date\n",
    "            article['url'] = url\n",
    "            if date in get_date:\n",
    "                # 排除公告 \n",
    "                if ('[公告]' not in article['title'][:4]) and ('[MobileComm]' not in article['title'][:12]):   \n",
    "                    articles.append(article)\n",
    "\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  獲取當篇文章內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_content(url):\n",
    "    my_headers = {'cookie': 'over18=1;'}\n",
    "    resp = requests.get(url, headers = my_headers)\n",
    "    bs = BeautifulSoup(resp.content, 'html.parser')\n",
    "    content = bs.find(id='main-content')\n",
    "    #cut = '※ 發信站: 批踢踢實業坊(ptt.cc),'\n",
    "    cut = '\\n--\\n'\n",
    "    \n",
    "    #有文章內容上方的時間欄才抓取\n",
    "    try:\n",
    "    \n",
    "        p_time_main = content.find_all('div')[3].text.split('時間')[1]    \n",
    "       \n",
    "     \n",
    "        # main_content = content.text.split(cut)[0].split(p_time_main)[1]\n",
    "        # 0423 modify 主文中以，取代換行'\\n'及空白' '    \n",
    "        main_content = content.text.split(cut)[0].split(p_time_main)[1].replace('\\n','，').replace(' ','，')\n",
    "        \n",
    "        main_time = content.find_all('span',class_='article-meta-value')[-1].text\n",
    "\n",
    "        push_content = content.find_all(class_='push')\n",
    "        # p_content_list include [tag, account, push_content, p_time]\n",
    "        p_content_list = []\n",
    "        for p in push_content:\n",
    "            p_content = []\n",
    "            tag = p.find_all('span')[0].text\n",
    "            account = p.find_all('span')[1].text\n",
    "            if p.find_all('span')[2].text != ':':\n",
    "                push_content = p.find_all('span')[2].text.split(': ')[1]\n",
    "            else:\n",
    "                push_content = ''\n",
    "\n",
    "            p_time = p.find_all('span')[3].text.replace('\\n','')\n",
    "\n",
    "            p_content.append(tag)\n",
    "            p_content.append(account)\n",
    "            p_content.append(push_content)\n",
    "            p_content.append(p_time)\n",
    "\n",
    "            p_content_list.append(p_content)\n",
    "\n",
    "\n",
    "        return main_time,main_content, p_content_list\n",
    "    \n",
    "    except:\n",
    "        print('\\033[1;35m @@ Incorrect content! \\033[0m') #改變文字顏色\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save content to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_content(articles):  # save current page content to the list\n",
    "    \n",
    "    cp_ar = []\n",
    "    \n",
    "    for ar in articles:\n",
    "        #有內容才append\n",
    "        if ar_content(ar['url']):\n",
    "            #0426月 -> /, 日->/\n",
    "            date = ar['date'].replace('月','/').replace('日','/')\n",
    "            main_time = ar_content(ar['url'])[0]\n",
    "            #0426 add year\n",
    "            year = main_time.split(' ')[-1]\n",
    "            source = ar['source']\n",
    "            upvote = ar['upvote']\n",
    "            url = ar['url']\n",
    "            author = ar['author']\n",
    "            title = ar['title']\n",
    "\n",
    "            main_content = ar_content(ar['url'])[1]\n",
    "            all_re_content = ar_content(ar['url'])[2]\n",
    "\n",
    "\n",
    "\n",
    "            #主文\n",
    "            current_main = []\n",
    "            #0426 year\n",
    "            current_main.append(year + '/' + date)            \n",
    "            current_main.append(main_time)            \n",
    "            current_main.append(source)\n",
    "            current_main.append(upvote)\n",
    "            current_main.append(url)\n",
    "            current_main.append(author)\n",
    "            current_main.append(title)\n",
    "            current_main.append(main_content)\n",
    "            current_main.append('') # re_tag\n",
    "            current_main.append('') # re_author\n",
    "            current_main.append('') # re_content\n",
    "            current_main.append('') # re_time\n",
    "            current_main.append('主文') # type\n",
    "\n",
    "            cp_ar.append(current_main)\n",
    "\n",
    "            for re in all_re_content:  \n",
    "                current_re = []    \n",
    "                # 回文\n",
    "                #0426 year \n",
    "                current_re.append(year + '/' + date)\n",
    "                current_re.append(main_time)\n",
    "                current_re.append(source)\n",
    "                current_re.append(upvote)\n",
    "                current_re.append(url)\n",
    "                current_re.append(author)\n",
    "                current_re.append(title)\n",
    "                # 0423 type為回文不放主文內容\n",
    "                #current_re.append(main_content)\n",
    "                current_re.append('')\n",
    "                current_re.append(re[0]) # tag\n",
    "                current_re.append(re[1]) # author\n",
    "                current_re.append(re[2].replace('=','≡')) # content\n",
    "                current_re.append(re[3]) # time\n",
    "                current_re.append('回文') # type\n",
    "                # 0423 同作者連續回文內容合併\n",
    "                if current_re[9] == cp_ar[-1][9]:\n",
    "                    cp_ar[-1][10] = cp_ar[-1][10] + '，' + current_re[10]\n",
    "                else:\n",
    "                    cp_ar.append(current_re)       \n",
    "\n",
    "            print(title)\n",
    "                \n",
    "    \n",
    "    return cp_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寫入excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = 'https://www.ptt.cc/bbs/MobileComm/index.html'\n",
    "gossiping = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
    "car = 'https://www.ptt.cc/bbs/car/index.html'\n",
    "creditcard = 'https://www.ptt.cc/bbs/creditcard/index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wb = xw.Book('ptt_mobile.xlsx') #讀取檔案\n",
    "wb = xw.Book()\n",
    "wb.save('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = wb.sheets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet.range('A1').value = [['發布日期', '發布時間', '來源', '主文tag', '網址', '主文作者', '標題', '主文','回文tag', '回文作者', '回文', '回文時間', '主文/回文']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04/12', '04/13']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 選取愈抓取日期, (start date, end date), end date 需為當日日期, 格式 03/1,03/10\n",
    "today = date.today().strftime(\"%m/%d\")\n",
    "days = getEveryDay('04/12',today)\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ptt.cc/bbs/car/index.html',\n",
       " 'https://www.ptt.cc/bbs/car/index5009.html',\n",
       " 'https://www.ptt.cc/bbs/car/index5008.html',\n",
       " 'https://www.ptt.cc/bbs/car/index5007.html',\n",
       " 'https://www.ptt.cc/bbs/car/index5006.html']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 依據date選取爬取頁面 (days, current_page)\n",
    "page = get_page_url(days, car)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[新聞] Toyota Crown全車系到齊！三款規格揭露\n",
      "[問題] BMW F06 640i 改裝推薦\n",
      "[問題] 抬頭顯示器+胎壓偵測整合推薦？\n",
      "[新聞] 新世代皮卡Ford Ranger開放預接單\n",
      "Re: [新聞] 新世代皮卡Ford Ranger開放預接單\n",
      "[心得] Prius 5 心得(日本自駕)\n",
      "[討論] 4/18上海車展-保時捷\n",
      "[討論] Prius PHEV怎麼不出休旅車\n",
      "[問車] 小休旅選擇請益\n",
      "[分享] 下午差點遲到的親身經歷\n",
      "[討論] 開名貴的車會閃比較遠?\n",
      "[問題] 台灣賓士能主導核章？\n",
      "Re: [分享] Ford 6.5代野馬一年油耗和保養分享\n",
      "[問題] 請問Toyota Camry 2008警報\n",
      "[問題] ALTIS 12代 排檔異音?\n",
      "[問題] 為何最近比較少看到竊車新聞?\n",
      "[心得] Yaris 經典版 購車心得\n",
      "[討論] 現在買2020的model 3會很盤嗎?\n",
      "[討論] T-Roc 330改裝 or 直上R\n",
      "Re: [討論] T-Roc 330改裝 or 直上R\n",
      "[菜單] 2023 Corolla Cross+Corolla Altis\n",
      "Re: [分享] Prius5可以訂車了\n",
      "[情報] GM正逐步取消AA跟CarPlay 改原生Android\n",
      "[問題] 稅制保護國產是不是要重新檢視國產成分？\n",
      "Re: [分享] Prius5可以訂車了\n",
      "[問題] 請問哪家超額險能保三千萬以上?\n",
      "[新聞] Lexus UX 300e大電池改款版本國內上市\n",
      "[分享] 自動駕駛計程車搭乘意願調查（抽商店禮卷\n",
      "[心得] 現代汽車 Tucson L b款 我當冤大頭的經過\n",
      "[新聞] MG Cyberster電動小跑車 500hp動力有點搞\n",
      "[新聞] 探頭確認過！擎天崗遊客「超認真倒車」\n",
      "[問題]領牌車的付款流程請益\n",
      "Re: [閒聊] 新竹某國小前面\n",
      "[問題] 插隊問題\n",
      "[問題] 隔熱紙請益\n",
      "[新聞] Range Rover SV正式在台上市，售價845萬\n",
      "[問題] RX200t 跑的贏 330i 嗎?\n",
      "[電車] Model 3 HIGHLAND 流出\n",
      "[討論] 國道休息站停車場應該要收費嗎？\n",
      "Re: [閒聊] 新竹某國小前面\n",
      "Re: [問題] 為什麼特斯拉造肇事率這麼高?\n",
      "[新聞] 行人地獄再現！駕駛無視導護闖紅燈 差點撞上斑馬線學童\n",
      "[新聞] Toyota最新氫能電動車MIRAI在台首度亮相\n",
      "Fw: [新聞] 新竹轎車硬闖紅燈急煞險撞 (加拿大安省罰則)\n",
      "[情報] Toyota日本官網更新CROWN系列資訊\n",
      "[新聞] Toyota 新社長上任宣誓加速電動化，3 年\n",
      "[新聞] Opel Grandland確定4月18日上市\n",
      "[新聞] BMW XM Label Red上海展前正式曝光　748\n",
      "[新聞] Toyota氫氣車台灣首次亮相！未來加氫費\n",
      "[分享] Ford 6.5代野馬一年油耗和保養分享\n",
      "[討論] 只差一點點會停機械車位嗎？\n",
      "Re: [討論] ORO胎壓偵測器自燃疑問\n",
      "[新聞] Nissan小改款X-Taril現身路測！最快今年便會發表\n",
      "Re: [閒聊] 新竹某國小前面\n",
      "Re: [問題] 為什麼特斯拉造肇事率這麼高?\n",
      "Re: [問題] 為什麼特斯拉造肇事率這麼高?\n",
      "Re: [新聞] 台灣大道行人地獄！日籍婦斑馬線遭左轉\n",
      "Re: [討論] 福特是不是比較不合台灣人胃口\n",
      "[新聞] 分析｜匯豐汽車被奧迪分手 癥結在這裡\n",
      "[分享] Prius5可以訂車了\n",
      "[新聞] 嘉義市凌晨2車路口相撞 1車衝入果園\n",
      "[討論] 好市多的focus wagon\n",
      "Re: [討論] ORO胎壓偵測器自燃疑問\n",
      "Re: [問題] 為什麼特斯拉造肇事率這麼高?\n",
      "[閒聊] 新竹某國小前面\n",
      "Re: [問題] 如果未來監視器都科技執法 台灣會變怎樣?\n",
      "[問題] 美國車子市占率\n",
      "[新聞] 前員工爆料！特斯拉「車載鏡頭影片大量外\n",
      "Re: [問題] 為什麼特斯拉造肇事率這麼高?\n",
      "Re: [問題] 如果未來監視器都科技執法 台灣會變怎樣?\n",
      "[新聞] Volkswagen The Touran榮登MPV銷售冠軍\n",
      "Re: [新聞] 分析｜匯豐汽車被奧迪分手 癥結在這裡\n",
      "[新聞] 特斯拉投資的鎳礦開採計畫讓森林裡的原\n",
      "\n",
      " ***** Finish *****\n"
     ]
    }
   ],
   "source": [
    "current_row = 2\n",
    "for p in page:\n",
    "    articles = ppt_web_crawler(p,days)\n",
    "    saved_content = cp_content(articles)\n",
    "    sheet.range('A' + str(current_row)).value = saved_content\n",
    "    current_row += len(saved_content)\n",
    "print('\\n ***** Finish *****')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
